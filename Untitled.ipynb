{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "\n",
    "from model import DCGAN\n",
    "from utils import pp, visualize, to_json, show_all_variables\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "epoch = 90000\n",
    "learning_rate = 0.0002\n",
    "beta1 = 0.5\n",
    "train_size = 802\n",
    "batch_size = 64\n",
    "imsize = 32\n",
    "dataset = \"pokemon/32x32x3\"\n",
    "input_fname_pattern = \"*.png\"\n",
    "checkpoint_dir = \"checkpoint\"\n",
    "sample_dir = \"samples_pokemon32\"\n",
    "train = True\n",
    "crop = False\n",
    "to_visualize = False\n",
    "generate_test_images = 100\n",
    "flags = tf.app.flags\n",
    "flags.DEFINE_integer(\"epoch\", epoch, \"Epoch to train [25]\")\n",
    "flags.DEFINE_float(\"learning_rate\", learning_rate, \"Learning rate of for adam [0.0002]\")\n",
    "flags.DEFINE_float(\"beta1\", beta1, \"Momentum term of adam [0.5]\")\n",
    "flags.DEFINE_integer(\"train_size\", train_size, \"The size of train images [np.inf]\")\n",
    "flags.DEFINE_integer(\"batch_size\", batch_size, \"The size of batch images [64]\")\n",
    "flags.DEFINE_integer(\"input_height\", imsize, \"The size of image to use (will be center cropped). [108]\")\n",
    "flags.DEFINE_integer(\"input_width\", imsize, \"The size of image to use (will be center cropped). If None, same value as input_height [None]\")\n",
    "flags.DEFINE_integer(\"output_height\", imsize, \"The size of the output images to produce [64]\")\n",
    "flags.DEFINE_integer(\"output_width\", imsize, \"The size of the output images to produce. If None, same value as output_height [None]\")\n",
    "flags.DEFINE_string(\"dataset\", dataset, \"The name of dataset [celebA, mnist, lsun]\")\n",
    "flags.DEFINE_string(\"input_fname_pattern\", input_fname_pattern, \"Glob pattern of filename of input images [*]\")\n",
    "flags.DEFINE_string(\"checkpoint_dir\", checkpoint_dir, \"Directory name to save the checkpoints [checkpoint]\")\n",
    "flags.DEFINE_string(\"sample_dir\", sample_dir, \"Directory name to save the image samples [samples]\")\n",
    "flags.DEFINE_boolean(\"train\", train, \"True for training, False for testing [False]\")\n",
    "flags.DEFINE_boolean(\"crop\", crop, \"True for training, False for testing [False]\")\n",
    "flags.DEFINE_boolean(\"visualize\", to_visualize, \"True for visualizing, False for nothing [False]\")\n",
    "flags.DEFINE_integer(\"generate_test_images\", generate_test_images, \"Number of images to generate during test. [100]\")\n",
    "FLAGS = flags.FLAGS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def main(_):\n",
    "  pp.pprint(flags.FLAGS.__flags)\n",
    "\n",
    "  if not os.path.exists(FLAGS.checkpoint_dir):\n",
    "    os.makedirs(FLAGS.checkpoint_dir)\n",
    "  if not os.path.exists(FLAGS.sample_dir):\n",
    "    os.makedirs(FLAGS.sample_dir)\n",
    "\n",
    "  run_config = tf.ConfigProto()\n",
    "  run_config.gpu_options.allow_growth=True\n",
    "\n",
    "  with tf.Session(config=run_config) as sess:\n",
    "    if dataset == 'mnist':\n",
    "      dcgan = DCGAN(\n",
    "          sess,\n",
    "          batch_size=batch_size,\n",
    "          sample_num=batch_size,\n",
    "          y_dim=10,\n",
    "          z_dim=generate_test_images,\n",
    "          dataset_name=dataset,\n",
    "          input_fname_pattern=input_fname_pattern,\n",
    "          crop=crop,\n",
    "          checkpoint_dir=checkpoint_dir,\n",
    "          sample_dir=sample_dir,\n",
    "          imsize=imsize)\n",
    "    else:\n",
    "      dcgan = DCGAN(\n",
    "          sess,\n",
    "          batch_size=FLAGS.batch_size,\n",
    "          sample_num=FLAGS.batch_size,\n",
    "          z_dim=FLAGS.generate_test_images,\n",
    "          dataset_name=FLAGS.dataset,\n",
    "          input_fname_pattern=FLAGS.input_fname_pattern,\n",
    "          crop=FLAGS.crop,\n",
    "          checkpoint_dir=FLAGS.checkpoint_dir,\n",
    "          sample_dir=FLAGS.sample_dir,\n",
    "          imsize= imsize)\n",
    "\n",
    "    show_all_variables()\n",
    "\n",
    "    if FLAGS.train:\n",
    "      dcgan.train(FLAGS)\n",
    "      print \"Done training lol\"\n",
    "    else:\n",
    "      if not dcgan.load(FLAGS.checkpoint_dir)[0]:\n",
    "        raise Exception(\"[!] Train a model first, then run test mode\")\n",
    "      \n",
    "\n",
    "    # to_json(\"./web/js/layers.js\", [dcgan.h0_w, dcgan.h0_b, dcgan.g_bn0],\n",
    "    #                 [dcgan.h1_w, dcgan.h1_b, dcgan.g_bn1],\n",
    "    #                 [dcgan.h2_w, dcgan.h2_b, dcgan.g_bn2],\n",
    "    #                 [dcgan.h3_w, dcgan.h3_b, dcgan.g_bn3],\n",
    "    #                 [dcgan.h4_w, dcgan.h4_b, None])\n",
    "\n",
    "    # Below is codes for visualization\n",
    "    OPTION = 1\n",
    "    #visualize(sess, dcgan, FLAGS, OPTION)\n",
    "    print \"Finishing..\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
