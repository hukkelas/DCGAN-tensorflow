{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "\n",
    "from model import DCGAN\n",
    "from utils import pp, visualize, to_json, show_all_variables\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "epoch = 90000\n",
    "learning_rate = 0.0002\n",
    "beta1 = 0.5\n",
    "model =\"cond\" #fc or cond \n",
    "activation_function  = tf.nn.tanh\n",
    "train_size = 802\n",
    "batch_size = 64\n",
    "imsize = 64\n",
    "dataset = \"pokemon/64x64x3\"\n",
    "input_fname_pattern = \"*.png\"\n",
    "checkpoint_dir = \"checkpoint64_cond\"\n",
    "sample_dir = \"samples_pokemons64_cond\"\n",
    "train = True\n",
    "crop = False\n",
    "to_visualize = False\n",
    "generate_test_images = 100\n",
    "flags = tf.app.flags\n",
    "flags.DEFINE_integer(\"epoch\", epoch, \"Epoch to train [25]\")\n",
    "flags.DEFINE_float(\"learning_rate\", learning_rate, \"Learning rate of for adam [0.0002]\")\n",
    "flags.DEFINE_float(\"beta1\", beta1, \"Momentum term of adam [0.5]\")\n",
    "flags.DEFINE_integer(\"train_size\", train_size, \"The size of train images [np.inf]\")\n",
    "flags.DEFINE_integer(\"batch_size\", batch_size, \"The size of batch images [64]\")\n",
    "flags.DEFINE_integer(\"input_height\", imsize, \"The size of image to use (will be center cropped). [108]\")\n",
    "flags.DEFINE_integer(\"input_width\", imsize, \"The size of image to use (will be center cropped). If None, same value as input_height [None]\")\n",
    "flags.DEFINE_integer(\"output_height\", imsize, \"The size of the output images to produce [64]\")\n",
    "flags.DEFINE_integer(\"output_width\", imsize, \"The size of the output images to produce. If None, same value as output_height [None]\")\n",
    "flags.DEFINE_string(\"dataset\", dataset, \"The name of dataset [celebA, mnist, lsun]\")\n",
    "flags.DEFINE_string(\"input_fname_pattern\", input_fname_pattern, \"Glob pattern of filename of input images [*]\")\n",
    "flags.DEFINE_string(\"checkpoint_dir\", checkpoint_dir, \"Directory name to save the checkpoints [checkpoint]\")\n",
    "flags.DEFINE_string(\"sample_dir\", sample_dir, \"Directory name to save the image samples [samples]\")\n",
    "flags.DEFINE_boolean(\"train\", train, \"True for training, False for testing [False]\")\n",
    "flags.DEFINE_boolean(\"crop\", crop, \"True for training, False for testing [False]\")\n",
    "flags.DEFINE_boolean(\"visualize\", to_visualize, \"True for visualizing, False for nothing [False]\")\n",
    "flags.DEFINE_integer(\"generate_test_images\", generate_test_images, \"Number of images to generate during test. [100]\")\n",
    "FLAGS = flags.FLAGS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 64,\n",
      " 'beta1': 0.5,\n",
      " 'checkpoint_dir': 'checkpoint64_cond',\n",
      " 'crop': False,\n",
      " 'dataset': 'pokemon/64x64x3',\n",
      " 'epoch': 90000,\n",
      " 'generate_test_images': 100,\n",
      " 'input_fname_pattern': '*.png',\n",
      " 'input_height': 64,\n",
      " 'input_width': 64,\n",
      " 'learning_rate': 0.0002,\n",
      " 'output_height': 64,\n",
      " 'output_width': 64,\n",
      " 'sample_dir': 'samples_pokemons64_cond',\n",
      " 'train': True,\n",
      " 'train_size': 802,\n",
      " 'visualize': False}\n",
      "---------\n",
      "Variables: name (type shape) [size]\n",
      "---------\n",
      "generator/g_h0_lin/Matrix:0 (float32_ref 118x8192) [966656, bytes: 3866624]\n",
      "generator/g_h0_lin/bias:0 (float32_ref 8192) [8192, bytes: 32768]\n",
      "generator/g_bn0/beta:0 (float32_ref 512) [512, bytes: 2048]\n",
      "generator/g_bn0/gamma:0 (float32_ref 512) [512, bytes: 2048]\n",
      "generator/g_h1/w:0 (float32_ref 5x5x256x530) [3392000, bytes: 13568000]\n",
      "generator/g_h1/biases:0 (float32_ref 256) [256, bytes: 1024]\n",
      "generator/g_bn1/beta:0 (float32_ref 256) [256, bytes: 1024]\n",
      "generator/g_bn1/gamma:0 (float32_ref 256) [256, bytes: 1024]\n",
      "generator/g_h2/w:0 (float32_ref 5x5x128x274) [876800, bytes: 3507200]\n",
      "generator/g_h2/biases:0 (float32_ref 128) [128, bytes: 512]\n",
      "generator/g_bn2/beta:0 (float32_ref 128) [128, bytes: 512]\n",
      "generator/g_bn2/gamma:0 (float32_ref 128) [128, bytes: 512]\n",
      "generator/g_h3/w:0 (float32_ref 5x5x64x146) [233600, bytes: 934400]\n",
      "generator/g_h3/biases:0 (float32_ref 64) [64, bytes: 256]\n",
      "generator/g_bn3/beta:0 (float32_ref 64) [64, bytes: 256]\n",
      "generator/g_bn3/gamma:0 (float32_ref 64) [64, bytes: 256]\n",
      "generator/g_h4/w:0 (float32_ref 5x5x3x82) [6150, bytes: 24600]\n",
      "generator/g_h4/biases:0 (float32_ref 3) [3, bytes: 12]\n",
      "discriminator/d_h0_conv/w:0 (float32_ref 5x5x21x21) [11025, bytes: 44100]\n",
      "discriminator/d_h0_conv/biases:0 (float32_ref 21) [21, bytes: 84]\n",
      "discriminator/d_h1_conv/w:0 (float32_ref 5x5x39x82) [79950, bytes: 319800]\n",
      "discriminator/d_h1_conv/biases:0 (float32_ref 82) [82, bytes: 328]\n",
      "discriminator/d_bn1/beta:0 (float32_ref 82) [82, bytes: 328]\n",
      "discriminator/d_bn1/gamma:0 (float32_ref 82) [82, bytes: 328]\n",
      "discriminator/d_h2_lin/Matrix:0 (float32_ref 21010x1024) [21514240, bytes: 86056960]\n",
      "discriminator/d_h2_lin/bias:0 (float32_ref 1024) [1024, bytes: 4096]\n",
      "discriminator/d_bn2/beta:0 (float32_ref 1024) [1024, bytes: 4096]\n",
      "discriminator/d_bn2/gamma:0 (float32_ref 1024) [1024, bytes: 4096]\n",
      "discriminator/d_h3_lin/Matrix:0 (float32_ref 1042x1) [1042, bytes: 4168]\n",
      "discriminator/d_h3_lin/bias:0 (float32_ref 1) [1, bytes: 4]\n",
      "Total size of variables: 27095366\n",
      "Total bytes of variables: 108381464\n",
      " [*] Reading checkpoints...\n",
      " [*] Failed to find a checkpoint\n",
      " [!] Load failed...\n",
      "Epoch: [ 0] [  11/  12] time: 3.2037, d_loss: 1.36823988, g_loss: 0.75351608\n",
      "Sample saved\n",
      "Epoch: [10] [  11/  12] time: 17.1297, d_loss: 1.06032801, g_loss: 0.83067179\n",
      "Sample saved\n",
      "Epoch: [20] [  11/  12] time: 30.9837, d_loss: 1.00762784, g_loss: 0.84615761\n",
      "Sample saved\n",
      "Epoch: [30] [  11/  12] time: 44.7906, d_loss: 0.93736696, g_loss: 1.00217819\n",
      "Sample saved\n",
      "Epoch: [40] [  11/  12] time: 59.1489, d_loss: 0.67005348, g_loss: 1.17106867\n",
      "Sample saved\n",
      "Epoch: [50] [  11/  12] time: 73.0343, d_loss: 0.87036926, g_loss: 1.27795804\n",
      "Sample saved\n",
      "Epoch: [60] [  11/  12] time: 87.3354, d_loss: 0.84890199, g_loss: 1.19748211\n",
      "Sample saved\n",
      "Epoch: [70] [  11/  12] time: 101.9308, d_loss: 0.63736957, g_loss: 1.67572296\n",
      "Sample saved\n",
      "Epoch: [80] [  11/  12] time: 116.0466, d_loss: 0.49173829, g_loss: 1.38194823\n",
      "Sample saved\n",
      "Epoch: [90] [  11/  12] time: 130.0278, d_loss: 0.44883221, g_loss: 1.41424072\n",
      "Sample saved\n",
      "Epoch: [100] [  11/  12] time: 143.7423, d_loss: 0.53629231, g_loss: 1.63978672\n",
      "Sample saved\n",
      "Epoch: [110] [  11/  12] time: 158.2116, d_loss: 0.48305699, g_loss: 1.52953005\n",
      "Sample saved\n",
      "Epoch: [120] [  11/  12] time: 172.3073, d_loss: 0.36193323, g_loss: 1.83290648\n",
      "Sample saved\n",
      "Epoch: [130] [  11/  12] time: 185.8915, d_loss: 0.57494360, g_loss: 1.55622017\n",
      "Sample saved\n",
      "Epoch: [140] [  11/  12] time: 199.3254, d_loss: 0.48552769, g_loss: 1.35728884\n",
      "Sample saved\n",
      "Epoch: [150] [  11/  12] time: 213.0389, d_loss: 0.57469082, g_loss: 1.74154615\n",
      "Sample saved\n",
      "Epoch: [160] [  11/  12] time: 226.5453, d_loss: 0.56975281, g_loss: 1.37740910\n",
      "Sample saved\n",
      "Epoch: [170] [  11/  12] time: 239.8953, d_loss: 0.16780818, g_loss: 2.24775076\n",
      "Sample saved\n",
      "Epoch: [180] [  11/  12] time: 253.2247, d_loss: 0.69437736, g_loss: 1.52197599\n",
      "Sample saved\n",
      "Epoch: [190] [  11/  12] time: 266.9966, d_loss: 0.29329842, g_loss: 1.98022020\n",
      "Sample saved\n",
      "Epoch: [200] [  11/  12] time: 281.0230, d_loss: 0.15508513, g_loss: 2.28554630\n",
      "Sample saved\n",
      "Epoch: [210] [  11/  12] time: 295.0032, d_loss: 0.28953117, g_loss: 2.08997226\n",
      "Sample saved\n",
      "Epoch: [220] [  11/  12] time: 308.6037, d_loss: 0.33584207, g_loss: 1.72724879\n",
      "Sample saved\n",
      "Epoch: [230] [  11/  12] time: 321.8076, d_loss: 0.20905620, g_loss: 1.99718094\n",
      "Sample saved\n",
      "Epoch: [240] [  11/  12] time: 335.2463, d_loss: 0.56918710, g_loss: 1.97446465\n",
      "Sample saved\n",
      "Epoch: [250] [  11/  12] time: 348.4038, d_loss: 0.44967312, g_loss: 1.64777279\n",
      "Sample saved\n",
      "Epoch: [260] [  11/  12] time: 361.7115, d_loss: 0.15626062, g_loss: 2.31401396\n",
      "Sample saved\n",
      "Epoch: [270] [  11/  12] time: 375.4466, d_loss: 0.41346133, g_loss: 2.28258014\n",
      "Sample saved\n",
      "Epoch: [280] [  11/  12] time: 388.7239, d_loss: 0.38100439, g_loss: 1.88557899\n",
      "Sample saved\n",
      "Epoch: [290] [  11/  12] time: 402.2398, d_loss: 0.21262157, g_loss: 1.99640715\n",
      "Sample saved\n",
      "Epoch: [300] [  11/  12] time: 415.7241, d_loss: 0.42282134, g_loss: 1.91876352\n",
      "Sample saved\n",
      "Epoch: [310] [  11/  12] time: 429.0346, d_loss: 0.20772511, g_loss: 2.63378835\n",
      "Sample saved\n",
      "Epoch: [320] [  11/  12] time: 442.5455, d_loss: 0.34342927, g_loss: 1.84102225\n",
      "Sample saved\n",
      "Epoch: [330] [  11/  12] time: 455.6957, d_loss: 0.32593429, g_loss: 1.88819098\n",
      "Sample saved\n",
      "Epoch: [340] [  11/  12] time: 469.0452, d_loss: 0.10114563, g_loss: 3.26125813\n",
      "Sample saved\n",
      "Epoch: [350] [  11/  12] time: 482.2954, d_loss: 0.25242287, g_loss: 1.97082758\n",
      "Sample saved\n",
      "Epoch: [360] [  11/  12] time: 495.5912, d_loss: 0.24812932, g_loss: 2.59758401\n",
      "Sample saved\n",
      "Epoch: [370] [  11/  12] time: 509.8206, d_loss: 0.09719965, g_loss: 2.97142839\n",
      "Sample saved\n"
     ]
    }
   ],
   "source": [
    "def main(_):\n",
    "  pp.pprint(flags.FLAGS.__flags)\n",
    "\n",
    "  if not os.path.exists(FLAGS.checkpoint_dir):\n",
    "    os.makedirs(FLAGS.checkpoint_dir)\n",
    "  if not os.path.exists(FLAGS.sample_dir):\n",
    "    os.makedirs(FLAGS.sample_dir)\n",
    "\n",
    "  run_config = tf.ConfigProto()\n",
    "  run_config.gpu_options.allow_growth=True\n",
    "\n",
    "  with tf.Session(config=run_config) as sess:\n",
    "    if dataset == 'mnist':\n",
    "      dcgan = DCGAN(\n",
    "          sess,\n",
    "          batch_size=batch_size,\n",
    "          sample_num=batch_size,\n",
    "          y_dim=10,\n",
    "          z_dim=generate_test_images,\n",
    "          dataset_name=dataset,\n",
    "          input_fname_pattern=input_fname_pattern,\n",
    "          crop=crop,\n",
    "          checkpoint_dir=checkpoint_dir,\n",
    "          sample_dir=sample_dir,\n",
    "          imsize=imsize)\n",
    "    else:\n",
    "      dcgan = DCGAN(\n",
    "          sess,\n",
    "          batch_size=FLAGS.batch_size,\n",
    "          sample_num=FLAGS.batch_size,\n",
    "          z_dim=FLAGS.generate_test_images,\n",
    "          dataset_name=FLAGS.dataset,\n",
    "          input_fname_pattern=FLAGS.input_fname_pattern,\n",
    "          y_dim=18,\n",
    "          crop=FLAGS.crop,\n",
    "          checkpoint_dir=FLAGS.checkpoint_dir,\n",
    "          sample_dir=FLAGS.sample_dir,\n",
    "          imsize= imsize,\n",
    "          gen_activation_function=activation_function,\n",
    "          model=model)\n",
    "\n",
    "    show_all_variables()\n",
    "\n",
    "    if FLAGS.train:\n",
    "      dcgan.train(FLAGS)\n",
    "      print \"Done training lol\"\n",
    "    else:\n",
    "      if not dcgan.load(FLAGS.checkpoint_dir)[0]:\n",
    "        raise Exception(\"[!] Train a model first, then run test mode\")\n",
    "      \n",
    "\n",
    "    # to_json(\"./web/js/layers.js\", [dcgan.h0_w, dcgan.h0_b, dcgan.g_bn0],\n",
    "    #                 [dcgan.h1_w, dcgan.h1_b, dcgan.g_bn1],\n",
    "    #                 [dcgan.h2_w, dcgan.h2_b, dcgan.g_bn2],\n",
    "    #                 [dcgan.h3_w, dcgan.h3_b, dcgan.g_bn3],\n",
    "    #                 [dcgan.h4_w, dcgan.h4_b, None])\n",
    "\n",
    "    # Below is codes for visualization\n",
    "    OPTION = 1\n",
    "    #visualize(sess, dcgan, FLAGS, OPTION)\n",
    "    print \"Finishing..\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
